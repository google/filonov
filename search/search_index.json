{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Filonov","text":"<p>When dealing with huge amounts of media (video, images, texts) it might be hard to identify which creative approaches work the best since actual performance is usually evaluated on a single medium.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Fetching media: Downloading media info from various sources (i.e. Google Ads)</li> <li>Tagging media: Getting content of each media as a tag.</li> <li>Finding similar media: Find similar media and group them into clusters.</li> <li>Visualizing media: Ready to use dashboard for understanding media performance on tag, media, and cluster levels.</li> </ul>"},{"location":"#installation","title":"Installation","text":"pipuv <pre><code>pip install filonov\n</code></pre> <pre><code>uv add filonov\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p><code>filonov</code> consists of two major parts:</p> <ul> <li>Data Pipeline</li> <li>Data Visualization</li> </ul>"},{"location":"#generating-files","title":"Generating files","text":"cliUI <pre><code>filonov \\\n  --source googleads \\\n  --googleads.account=ACCOUNT_ID \\\n  --media-type IMAGE\n</code></pre> <pre><code>filonov-ui\n</code></pre>"},{"location":"#visualizing-data","title":"Visualizing data","text":""},{"location":"#serveless","title":"Serveless","text":"<p>Data Visualization is a web application uniformly accessible for all users from http://filonov-ai.web.app.</p> <p>It's deployed to Firebase Static Hosting and implemented as serverless web application where users can open data files generated with the Data Pipeline.</p>"},{"location":"#self-hosted","title":"Self-hosted","text":"<p>Filonov UI can be run locally.</p> <ul> <li>Install the dependencies</li> </ul> <pre><code>npm install\n</code></pre> <ul> <li> <p>Start the app in development mode (hot-code reloading, error reporting, etc.) <pre><code>quasar dev\n</code></pre></p> </li> <li> <p>Build the app for production <pre><code>quasar build\n</code></pre></p> </li> </ul>"},{"location":"fetching/bq/","title":"BigQuery","text":""},{"location":"fetching/bq/#installation","title":"Installation","text":"<p>Fetching from BigQuery requires installing extra dependency.</p> pipuv <pre><code>pip install media-fetching[bq]\n</code></pre> <pre><code>uv pip install media-fetching[bq]\n</code></pre>"},{"location":"fetching/bq/#usage","title":"Usage","text":"clipython <pre><code>media-fetcher \\\n  --source bq \\\n  --bq.table=project.dataset.table\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import sql\n\nfetcher = media_fetching.MediaFetchingService(source='bq')\nrequest = sql.BigQueryFetchingParameters(\n  table='project.dataset.table'\n)\nreport = fetcher.fetch(request)\n</code></pre> <p>Reports can be written and processed. Learn more at garf.</p>"},{"location":"fetching/bq/#parameters","title":"Parameters","text":""},{"location":"fetching/bq/#mandatory","title":"Mandatory","text":"<ul> <li><code>table</code> - Fully qualified name of the table in BigQuery (in <code>project.dataset.table</code> format).</li> </ul>"},{"location":"fetching/bq/#optional","title":"Optional","text":"<ul> <li><code>media_identifier</code> - column name in the table representing path to the media.</li> <li><code>media_name</code> - column name in the table representing name of the media.</li> <li><code>metrics</code> - column names of metrics to get from the table.</li> <li><code>segments</code> - column names of dimensions to get from the table.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source bq \\\n  --bq.table=project.dataset.table \\\n  --bq.media-identifier=media_url \\\n  --bq.media-name=media_name \\\n  --bq.metrics=clicks,impressions \\\n  --bq.segments=date\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import sql\n\nfetcher = media_fetching.MediaFetchingService(source='bq')\nrequest = sql.BigQueryFetchingParameters(\n  table='project.dataset.table',\n  media_identifier='media_url',\n  media_name='media_name',\n  metrics=['clicks', 'impressions'],\n  segments=['date'],\n\n)\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/enriching/","title":"Available extra info modules","text":"<p>Source customizations are performed via <code>--extra-info module.method</code> syntax (i.e. <code>--extra-info tagging.languages,googleads.main_geo</code>)</p>"},{"location":"fetching/enriching/#prerequisites","title":"Prerequisites","text":"<ul> <li>(Optional) If using <code>tagging</code> enricher - media-tagger must be configured</li> </ul>"},{"location":"fetching/enriching/#usage","title":"Usage","text":"<p>Suppose we want to use Gemini to identify language of each media found in a file <code>media.csv</code>.</p> clipython <pre><code>media-fetcher \\\n  --source file \\\n  --file.path=media.csv \\\n  --media-type IMAGE \\\n  --extra_info tagging.language\n</code></pre> <pre><code>import media_fetching\n\nfetcher = media_fetching.MediaFetchingService(source='file')\nrequest = {'path': 'media.csv', 'extra_info': ['tagging.language']}\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/enriching/#supported-enrichers","title":"Supported enrichers","text":""},{"location":"fetching/enriching/#googleads","title":"googleads","text":"<ul> <li>main_geo - identifies main spending country for a media.</li> <li>approval_rate - calculates approval rate (from 0 to 1) for each media.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source googleads \\\n  --googleads.account=ACCOUNT_ID \\\n  --media-type IMAGE \\\n  --extra_info googleads.main_geo,googleads.approval_rate\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import googleads\n\nfetcher = media_fetching.MediaFetchingService(source='googleads')\nrequest = googleads.GoogleAdsFetchingParameters(\n  account='ACCOUNT_ID',\n  media_type='IMAGE',\n  extra_info=['googleads.main_geo', 'googleads.approval_rate'],\n)\n\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/enriching/#tagging","title":"tagging","text":"<ul> <li>language - identifies language of a media.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source googleads \\\n  --googleads.account=ACCOUNT_ID \\\n  --media-type IMAGE \\\n  --extra_info tagging.language\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import googleads\n\nfetcher = media_fetching.MediaFetchingService(source='googleads')\nrequest = googleads.GoogleAdsFetchingParameters(\n  account='ACCOUNT_ID',\n  media_type='IMAGE',\n  extra_info=['tagging.language'],\n)\n\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/enriching/#youtube","title":"youtube","text":"<ul> <li>language - identifies language of YouTube Video based on YouTube Data API.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source googleads \\\n  --googleads.account=ACCOUNT_ID \\\n  --media-type YOUTUBE_VIDEO \\\n  --extra_info youtube.language\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import googleads\n\nfetcher = media_fetching.MediaFetchingService(source='googleads')\nrequest = googleads.GoogleAdsFetchingParameters(\n  account='ACCOUNT_ID',\n  media_type='IMAGE',\n  extra_info=['youtube.language'],\n)\n\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/file/","title":"File","text":"<p>Fetching from a file expects either local or remote CSV.</p>"},{"location":"fetching/file/#usage","title":"Usage","text":"clipython <pre><code>media-fetcher \\\n  --source file \\\n  --file.path=PATH_TO_FILE.csv\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import file\n\nfetcher = media_fetching.MediaFetchingService(source='file')\nrequest = file.FileFetchingParameters(path='PATH_TO_FILE.csv')\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/file/#parameters","title":"Parameters","text":""},{"location":"fetching/file/#mandatory","title":"Mandatory","text":"<ul> <li>path=PATH_TO_FILE</li> <li><code>path</code> - Path to local or remote CSV file..</li> </ul>"},{"location":"fetching/file/#optional","title":"Optional","text":"<ul> <li><code>media_identifier</code> - column name in the table representing path to the media.</li> <li><code>media_name</code> - column name in the table representing name of the media.</li> <li><code>metrics</code> - column names of metrics to get from the table.</li> <li><code>segments</code> - column names of dimensions to get from the table.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source file \\\n  --file.path=PATH_TO_FILE.csv \\\n  --file.media-identifier=media_url \\\n  --file.media-name=media_name \\\n  --file.metrics=clicks,impressions \\\n  --file.segments=date\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import file\n\nfetcher = media_fetching.MediaFetchingService(source='file')\nrequest = file.FileFetchingParameters(\n  path='PATH_TO_FILE.csv',\n  media_identifier='media_url',\n  media_name='media_name',\n  metrics=['clicks', 'impressions'],\n  segments=['date'],\n\n)\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/googleads/","title":"Getting data from Google Ads","text":"<p>You can get various media performance data (i.e. assets) from various campaigns in Google Ads.</p>"},{"location":"fetching/googleads/#prerequisites","title":"Prerequisites","text":"<ul> <li>Google Ads API enabled and configured</li> </ul>"},{"location":"fetching/googleads/#usage","title":"Usage","text":"clipython <pre><code>media-fetcher \\\n  --source googleads \\\n  --googleads.account=ACCOUNT_ID \\\n  --media-type IMAGE\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import googleads\n\nfetcher = media_fetching.MediaFetchingService(source='googleads')\nrequest = googleads.GoogleAdsFetchingParameters(\n  account='ACCOUNT_ID',\n  media_type='IMAGE',\n)\nreport = fetcher.fetch(request)\n</code></pre> <p>Reports can be written and processed. Learn more at garf.</p>"},{"location":"fetching/googleads/#parameters","title":"Parameters","text":""},{"location":"fetching/googleads/#mandatory","title":"Mandatory","text":"<ul> <li><code>account</code> - Google Ads account to get data from. Can be either MCC or child account.</li> </ul>"},{"location":"fetching/googleads/#optional","title":"Optional","text":"<ul> <li><code>ads-config</code> - Path to <code>google-ads.yaml</code> file. If not provided then:<ul> <li>Environmental variable <code>GOOGLE_ADS_CONFIGURATION_FILE_PATH</code></li> <li>Searched <code>$HOME</code> directory as <code>google-ads.yaml</code>.</li> </ul> </li> <li><code>campaign-types</code> - Type of campaigns to get data from. Choose one of the following or select option <code>all</code> to get all available media of a single media type.<ul> <li><code>pmax</code></li> <li><code>demandgen</code></li> <li><code>search</code></li> <li><code>display</code></li> <li><code>app</code></li> <li><code>video</code></li> </ul> </li> <li><code>start-date</code> - First date of the period in <code>YYYY-MM-DD</code> format (i.e. <code>2025-01-01</code>). Defaults to 30 days ago.</li> <li><code>end-date</code> - Last date of the period in <code>YYYY-MM-DD</code> format. Defaults to yesterday.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source googleads \\\n  --media-type IMAGE \\\n  --googleads.account=ACCOUNT_ID \\\n  --googleads.campaign-types=pmax,demandgen \\\n  --googleads.start-date=2025-01-01 \\\n  --googleads.end-date=2025-01-31 \\\n  --googleads.ads-config=google-ads-custom.yaml\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import googleads\n\nfetcher = media_fetching.MediaFetchingService(source='googleads')\nrequest = googleads.GoogleAdsFetchingParameters(\n  account='ACCOUNT_ID',\n  media_type='IMAGE',\n  campaign_types=['demandgen', 'pmax'],\n  start_date='2025-01-01',\n  end_date='2025-01-31',\n  ads_config='google-ads-custom.yaml',\n)\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/overview/","title":"Overview","text":"<p><code>media-fetcher</code> performs fetching of supported media from various sources.</p> <p>It gives you information on a single media coupled with its performance.</p>"},{"location":"fetching/overview/#supported-sources","title":"Supported sources","text":"<ul> <li>googleads - fetch media performance metrics from a Google Ads account / MCC.</li> <li>youtube - fetch public videos from a YouTube channel.</li> <li>file - load media performance metrics from CSV files</li> <li>bq - load media performance metrics from BigQuery table.</li> <li>sql - load media performance metrics from SqlAlchemy supported DB.</li> </ul>"},{"location":"fetching/overview/#installation","title":"Installation","text":"pipuv <pre><code>pip install media-fetching\n</code></pre> <pre><code>uv add media-fetching\n</code></pre>"},{"location":"fetching/overview/#usage","title":"Usage","text":"<p>Once <code>media-fetcher</code> is installed you can call it:</p> <p><pre><code>media-fetcher \\\n  --source &lt;MEDIA_SOURCE&gt; \\\n  --media-type &lt;MEDIA_TYPE&gt; \\\n  --writer &lt;WRITER_TYPE&gt; \\\n  --output &lt;OUTPUT_FILE_NAME&gt;\n</code></pre> where:</p> <ul> <li><code>&lt;SOURCE&gt;</code> - source of media data, one of supported sources.</li> <li><code>&lt;MEDIA_TYPE&gt;</code> - type of media, one of supported media.</li> <li><code>&lt;WRITER_TYPE&gt;</code> - writer identifier (check available options at garf-io library).</li> <li><code>&lt;OUTPUT_FILE_NAME&gt;</code> - where to store the fetched data (by default <code>media_results</code>).</li> </ul>"},{"location":"fetching/sql/","title":"SQL DB","text":""},{"location":"fetching/sql/#installation","title":"Installation","text":"<p>Fetching from Databases supported by SqlAlchemy requires installing extra dependency.</p> pipuv <pre><code>pip install media-fetching[sql]\n</code></pre> <pre><code>uv pip install media-fetching[sql]\n</code></pre>"},{"location":"fetching/sql/#installing-db-drivers","title":"Installing DB drivers","text":"<p>Depending on your DB you might need to install a specific DB driver for SqlAlchemy.</p> <ul> <li>Postgres</li> <li>MySQL</li> <li>External</li> </ul>"},{"location":"fetching/sql/#usage","title":"Usage","text":"clipython <pre><code>media-fetcher \\\n  --source sqldb \\\n  --sqldb.connection_string=sqlite:///media_results.db \\\n  --sqldb.table=table_name\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import sql\n\nfetcher = media_fetching.MediaFetchingService(source='sqldb')\nrequest = sql.SqlAlchemyQueryFetchingParameters(\n  connection_string='sqlite:///media_results.db',\n  table='table_name'\n)\nreport = fetcher.fetch(request)\n</code></pre> <p>Reports can be written and processed. Learn more at garf.</p>"},{"location":"fetching/sql/#parameters","title":"Parameters","text":""},{"location":"fetching/sql/#mandatory","title":"Mandatory","text":"<ul> <li><code>connection_string</code> - Database URL in SQLAlchemy format.</li> <li><code>table</code> - Name of a table in the database.</li> </ul>"},{"location":"fetching/sql/#optional","title":"Optional","text":"<ul> <li><code>media_identifier</code> - column name in the table representing path to the media.</li> <li><code>media_name</code> - column name in the table representing name of the media.</li> <li><code>metrics</code> - column names of metrics to get from the table.</li> <li><code>segments</code> - column names of dimensions to get from the table.</li> </ul> clipython <pre><code>media-fetcher \\\n  --source sqldb \\\n  --sqldb.connection-string=sqlite:///media_results.db \\\n  --sqldb.table=table_name \\\n  --sqldb.media-identifier=media_url \\\n  --sqldb.media-name=media_name \\\n  --sqldb.metrics=clicks,impressions \\\n  --sqldb.segments=date\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import sql\n\nfetcher = media_fetching.MediaFetchingService(source='sqldb')\nrequest = sql.SqlAlchemyQueryFetchingParameters(\n  connection_string='sqlite:///media_results.db',\n  table='table_name'\n  media_identifier='media_url',\n  media_name='media_name',\n  metrics=['clicks', 'impressions'],\n  segments=['date'],\n\n)\nreport = fetcher.fetch(request)\n</code></pre>"},{"location":"fetching/youtube/","title":"Getting data from YouTube channel","text":"<p>You can extract video performance data (<code>likes</code> and <code>views</code>) from publicly available video in YouTube channel.</p>"},{"location":"fetching/youtube/#prerequisites","title":"Prerequisites","text":"<ul> <li>YouTube Data API enabled and configured</li> </ul>"},{"location":"fetching/youtube/#usage","title":"Usage","text":"clipython <pre><code>media-fetcher \\\n  --source youtube \\\n  --youtube.account=CHANNEL_ID\n</code></pre> <pre><code>import media_fetching\nfrom media_fetching.sources import youtube\n\nfetcher = media_fetching.MediaFetchingService(source='youtube')\nrequest = youtube.YouTubeFetchingParameters(\n  channel='CHANNEL_ID',\n)\nreport = fetcher.fetch(request)\n</code></pre> <p>Reports can be written and processed. Learn more at garf.</p>"},{"location":"fetching/youtube/#parameters","title":"Parameters","text":""},{"location":"fetching/youtube/#mandatory","title":"Mandatory","text":"<ul> <li><code>channel</code> - YouTube channel Id.</li> </ul>"},{"location":"get-started/installation/","title":"Installation","text":""},{"location":"get-started/installation/#installing-filonov","title":"Installing filonov","text":""},{"location":"get-started/installation/#create-and-activate-virtual-environment","title":"Create and activate virtual environment","text":"pipuv <pre><code>python -m venv .venv\nsource .venv/bin/activate\n</code></pre> <pre><code>uv venv\nsource .venv/bin/activate\n</code></pre>"},{"location":"get-started/installation/#installation","title":"Installation","text":"pipuv <pre><code>pip install filonov\n</code></pre> <pre><code>uv add filonov\n</code></pre>"},{"location":"get-started/installation/#with-ui-support","title":"with UI support","text":"<p>In order to interact with data generation pipeline of <code>filonov</code> via UI you need install additional dependencies.</p> pipuv <pre><code>pip install filonov[ui]\n</code></pre> <pre><code>uv add filonov[ui]\n</code></pre>"},{"location":"get-started/installation/#with-server-support","title":"with server support","text":"<p>In order to call <code>filonov</code> via API you need install additional dependencies.</p> pipuv <pre><code>pip install filonov[server]\n</code></pre> <pre><code>uv add filonov[server]\n</code></pre>"},{"location":"get-started/quickstart/","title":"Quickstart","text":"<p><code>filonov</code> combines media fetching, tagging and similarity detection libraries in one utility and allows you to generate creative maps files to be visualized in http://filonov-ai.web.app</p> <p>You can use <code>filonov</code> in one of the following forms:</p> <ul> <li>CLI tool - use <code>filonov</code> utility in your terminal or shell scripts.</li> <li>Python library - import <code>filonov</code> library to use in your Python code.</li> <li>API endpoint - start FastAPI endpoint with <code>python -m filonov.entrypoints.server</code></li> </ul>"},{"location":"get-started/quickstart/#parameters","title":"Parameters","text":"<p>When generating creative map files with <code>filonov</code> you need to provide several elements:</p> <ul> <li><code>source</code> - where media performance data can be found, check supported sources.</li> <li><code>media-type</code> - one of supported media types.</li> <li><code>tagger</code> - one of supported taggers</li> </ul> <p>You can check full command structure here.</p>"},{"location":"get-started/quickstart/#example","title":"Example","text":"<p>As a simple example we can get Google Ads images from <code>GOOGLE_ADS_ACCOUNT_ID</code> account.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID\n</code></pre> <pre><code>import filonov\n\nservice = filonov.FilonovService()\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  source_parameters={'account': 'GOOGLE_ADS_ACCOUNT_ID'}\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\"\n  }\n}'\n</code></pre> <p>This will save <code>creative_map.json</code> file to the same directory where code is run.</p>"},{"location":"get-started/quickstart/#customization","title":"Customization","text":"<p><code>filonov</code> supports multiple customization options.</p>"},{"location":"get-started/quickstart/#source","title":"Source","text":"<p>You can configure which data you're getting from a source.</p> <p>As an example we can get images from DemandGen campaigns (instead of default App campaigns) when fetching data from <code>googleads</code> source.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID \\\n  --googleads.campaign-types=demandgen\n</code></pre> <pre><code>import filonov\n\nservice = filonov.FilonovService()\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  source_parameters={\n    'account': 'GOOGLE_ADS_ACCOUNT_ID',\n    'campaign_types': ['demandgen'],\n  }\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\",\n    \"campaign_types\": \"demandgen\"\n  }\n}'\n</code></pre> <p>For the full list of customization options please refer to sources section.</p>"},{"location":"get-started/quickstart/#tagger","title":"Tagger","text":"<p>You can configure how to tag data extracted from the source.</p> <p>As an example we can get 50 tags (instead of default 100) when performing tagging via <code>gemini</code>.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --tagger.n-tags=50 \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID\n</code></pre> <pre><code>import filonov\n\nservice = filonov.FilonovService()\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  tagger_parameters={'n_tags': 50},\n  source_parameters={'account': 'GOOGLE_ADS_ACCOUNT_ID'}\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"tagger_parameters\": {\n    \"n_tags\": 50\n  },\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\"\n  }\n}'\n</code></pre> <p>For the full list of customization options please refer to taggers section.</p>"},{"location":"get-started/quickstart/#similarity","title":"Similarity","text":"<p>You can fine-tune how similarity is calculated.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --similarity.custom-threshold=2 \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID\n</code></pre> <pre><code>import filonov\n\nservice = filonov.FilonovService()\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  similarity_parameters={'custom_threshold': 2},\n  source_parameters={'account': 'GOOGLE_ADS_ACCOUNT_ID'}\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"similarity_parameters\": {\n    \"custom_threshold\": 2\n  },\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\"\n  }\n}'\n</code></pre>"},{"location":"get-started/quickstart/#persistence","title":"Persistence","text":"<p>You can save results of tagging / similarity calculation in a database.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --db-uri CONNECTION_STRING_TO_DB \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID\n</code></pre> <pre><code>import filonov\nimport media_tagging\nfrom media_tagging.repositories import SqlAlchemyTaggingResultsRepository\n\nmedia_tagging_repository = SqlAlchemyTaggingResultsRepository(\n  CONNECTION_STRING_TO_DB\n)\nmedia_tagging_service = media_tagging.MediaTaggingService(\n  media_tagging_repository\n)\n\nservice = filonov.FilonovService(tagging_service=media_tagging_service)\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  source_parameters={'account': 'GOOGLE_ADS_ACCOUNT_ID'}\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <p>Expose <code>MEDIA_TAGGING_DB_URL</code> environmental variable and restart service. <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\"\n  }\n}'\n</code></pre></p>"},{"location":"get-started/quickstart/#trimming","title":"Trimming","text":"<p>You can exclude tags with score below certain threshold when performing similarity calculation.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID \\\n  --trim-tags-threshold 0.5\n</code></pre> <pre><code>import filonov\n\nservice = filonov.FilonovService()\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  source_parameters={'account': 'GOOGLE_ADS_ACCOUNT_ID'},\n  trim_tags_threshold=0.5,\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\"\n  },\n  \"trim_tags_threshold\": 0.5\n}'\n</code></pre>"},{"location":"get-started/quickstart/#output","title":"Output","text":"<p>By default the results are saved into <code>creative_map.json</code> file in the current folder.</p> <p>You can overwrite it with <code>output-name</code> option.</p> <p>Let's save map into <code>map1.json</code> file.</p> clipythoncurl <pre><code>filonov --source googleads --media-type IMAGE \\\n  --tagger gemini \\\n  --googleads.account=GOOGLE_ADS_ACCOUNT_ID \\\n  --output-name map1\n</code></pre> <pre><code>import filonov\n\nservice = filonov.FilonovService()\n\nrequest = filonov.CreativeMapGenerateRequest(\n  source='googleads',\n  media_type='IMAGE',\n  tagger='gemini',\n  source_parameters={'account': 'GOOGLE_ADS_ACCOUNT_ID'},\n  output_parameters={'output_name': 'map1'},\n)\n\ncreative_map = service.generate_creative_map(request)\ncreative_map.save('creative_map')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/creative_maps/generate:googleads' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"media_type\": \"IMAGE\",\n  \"tagger\": \"gemini\",\n  \"source_parameters\": {\n    \"account\": \"GOOGLE_ADS_ACCOUNT_ID\"\n  },\n  \"output_parameters\": {\n    \"output_name\": \"map1\"\n  }\n}'\n</code></pre>"},{"location":"get-started/quickstart/#command-structure","title":"Command structure","text":"<pre><code>filonov --source SOURCE \\\n  --media-type MEDIA_TYPE \\\n  --db-uri=CONNECTION_STRING \\\n  --tagger=TAGGER_TYPE \\\n  --SOURCE.PARAM=VALUE \\\n  --tagger.PARAM=VALUE \\\n  --output-name=FILE_NAME\n</code></pre>"},{"location":"similarity/clustering/","title":"Clustering","text":""},{"location":"similarity/clustering/#finding-similar-media","title":"Finding similar media","text":"<p><code>media-similarity</code> can take several media, tag them and combine them into clusters.</p> clipython <pre><code>media-similarity cluster image1.png image2.png image3.png \\\n  --media-type IMAGE \\\n  --tagger gemini\n</code></pre> <pre><code>from media_similarity import MediaClusteringRequest, MediaSimilarityService\n\nservice = MediaSimilarityService()\n\nrequest = MediaClusteringRequest(\n  media_paths=[\n    'image1.png',\n    'image2.png',\n    'image3.png',\n    ],\n    media_type='IMAGE',\n    tagger_type='gemini',\n)\n\nclusters = service.cluster_media(request)\n</code></pre>"},{"location":"similarity/clustering/#working-with-clusters","title":"Working with clusters","text":"<p>Once <code>cluster_media</code> is executed you get a <code>ClusteringResults</code> object which contains:</p> <ul> <li><code>clusters</code> - mapping between media url and its assigned cluster</li> <li><code>adaptive_threshold</code> - minimal value for defining similar media.</li> <li><code>graph</code> -mapping with nodes and edges.</li> </ul> <p>You can get clusters two ways:</p> <ul> <li>via <code>.clusters</code> property as a dict</li> <li>via <code>.to_garf_report</code> method as a GarfReport which contains two columns - <code>media_url</code> and <code>cluster_id</code>.</li> </ul>"},{"location":"similarity/comparison/","title":"Comparison","text":""},{"location":"similarity/comparison/#comparing-two-media","title":"Comparing two media","text":"<p>Somethings it's useful to understand why two media end up in the same or different clusters.</p> <p><code>media-similarity</code> can provide detailed information how two media as similar to each other.</p> <p>Please note that this requires persistence setup.</p> clipython <pre><code>media-similarity compare image1 image2 image3 \\\n  --media-type IMAGE \\\n  --db-uri=&lt;CONNECTION_STRING&gt;\n</code></pre> <pre><code>from media_similarity import MediaSimilarityComparisonRequest, MediaSimilarityService\n\nservice = MediaSimilarityService.from_connecting_string(\n  'sqlite:///tagging_results.db'\n)\n\nrequest = MediaSimilarityComparisonRequest(\n  media_paths=[\n    'image1.png',\n    'image2.png',\n    'image3.png',\n    ],\n    media_type='IMAGE',\n)\n\ncompared_media = service.compare_media(request)\n</code></pre>"},{"location":"similarity/overview/","title":"Overview","text":"<p><code>media-similarity</code> finds how similar media are and combines them into clusters.</p> <p>Similarity is calculated based on tags provided by <code>media-tagging</code> library and takes into account how many similar tags two media have.</p>"},{"location":"similarity/overview/#key-features","title":"Key features","text":"<ul> <li>Clusters media into groups of similar media.</li> <li>Finds the most similar media for a set of seed media.</li> <li>Performs detailed explanation why two media are consider similar.</li> </ul>"},{"location":"similarity/overview/#installation","title":"Installation","text":"pipuv <pre><code>pip install media-similarity\n</code></pre> <pre><code>uv add media-similarity\n</code></pre>"},{"location":"similarity/overview/#usage","title":"Usage","text":""},{"location":"similarity/overview/#clustering","title":"Clustering","text":"<p><code>media-similarity</code> can take several media, tag them and combine them into clusters.</p> clipython <pre><code>media-similarity cluster image1.png image2.png image3.png \\\n  --media-type IMAGE \\\n  --tagger gemini\n</code></pre> <p><code>cluster</code> commands writes data to local / remote storage via garf-io with the following columns:</p> <ul> <li><code>cluster_id</code> - id of a cluster medium belongs.</li> <li><code>media_url</code> - identifier of medium.</li> </ul> <pre><code>from media_similarity import MediaClusteringRequest, MediaSimilarityService\n\nservice = MediaSimilarityService()\n\nrequest = MediaClusteringRequest(\n  media_paths=[\n    'image1.png',\n    'image2.png',\n    'image3.png',\n    ],\n    media_type='IMAGE',\n    tagger_type='gemini',\n)\n\nclusters = service.cluster_media(request)\n</code></pre> <p><code>cluster_media</code> returns <code>ClusteringResults</code> object which contains the following properties:</p> <ul> <li><code>clusters</code> - mapping between medium and its assigned cluster id.</li> <li><code>adaptive_threshold</code> - threshold used to identify whether two media belong to the same cluster.</li> <li><code>graph_info</code> -  stores information on each medium and its relationship to other media.</li> </ul> <p><code>ClusteringResults</code> can be written to local / remote storage via garf-io with <code>to_garf_report</code> method with the following columns:</p> <ul> <li><code>cluster_id</code> - id of a cluster medium belongs.</li> <li><code>media_url</code> - identifier of medium.</li> </ul>"},{"location":"similarity/overview/#similarity-search","title":"Similarity Search","text":"<p><code>media-similarity</code> can search for similar media given a set of seed media.</p> <p>Please note that this requires persistence setup.</p> clipython <pre><code>media-similarity search image1 image2 \\\n  --media-type IMAGE \\\n  --db-uri=&lt;CONNECTION_STRING&gt;\n</code></pre> <p><code>search</code> commands writes data to local / remote storage via garf-io with the following columns:</p> <ul> <li><code>seed_media_identifier</code> - identifier of media used to perform a search.</li> <li><code>media_identifier</code> - identifier of found similar media.</li> <li><code>score</code> - similarity score showing how strong the connection between two media.</li> </ul> <pre><code>from media_similarity import MediaSimilaritySearchRequest, MediaSimilarityService\n\nservice = MediaSimilarityService.from_connecting_string(\n  'sqlite:///tagging_results.db'\n)\n\nrequest = MediaSimilaritySearchRequest(\n  media_paths=[\n    'image3.png',\n    ],\n    media_type='IMAGE',\n    n_results=1,\n)\n\nsimilar_media = service.find_similar_media(request)\n</code></pre> <p><code>find_similar_media</code> returns list of <code>SimilaritySearchResults</code> objects each containing the following properties:</p> <ul> <li><code>seed_media_identifier</code> - identifier of media used to perform a search.</li> <li><code>results</code> - identifiers of the most similar media with their similarity scores.</li> </ul> <p><code>SimilaritySearchResults</code> can be written to local / remote storage via garf-io with <code>to_garf_report</code> method with the following columns:</p> <ul> <li><code>cluster_id</code> - id of a cluster medium belongs.</li> <li><code>media_url</code> - identifier of medium.</li> </ul>"},{"location":"similarity/overview/#comparison","title":"Comparison","text":"<p><code>media-similarity</code> can provide detailed information how two media as similar to each other.</p> <p>Please note that this requires persistence setup.</p> clipython <pre><code>media-similarity compare image1 image2 image3 \\\n  --media-type IMAGE \\\n  --db-uri=&lt;CONNECTION_STRING&gt;\n</code></pre> <p><code>compare</code> commands writes data to local / remote storage via garf-io with the following columns:</p> <ul> <li><code>media_pair_identifier</code> - identifier of a media pair (pipe separated media ids of two media).</li> <li><code>score</code> - similarity score for media pair.</li> <li><code>similar_tags</code> - number of common tags between media.</li> <li><code>similarity_weight_normalized</code> - weight of similar tags normalized by inverse-document frequency.</li> <li><code>similarity_weight_unnormalized</code> - weight of similar tags.</li> <li><code>dissimilar_tags</code>- number of dissimilar tags between media.</li> <li><code>dissimilarity_weight_normalized</code> - weight of dissimilar tags normalized by inverse-document frequency.</li> <li><code>dissimilarity_weight_unnormalized</code> - weight of dissimilar tags.</li> </ul> <pre><code>from media_similarity import MediaSimilarityComparisonRequest, MediaSimilarityService\n\nservice = MediaSimilarityService.from_connecting_string(\n  'sqlite:///tagging_results.db'\n)\n\nrequest = MediaSimilarityComparisonRequest(\n  media_paths=[\n    'image1.png',\n    'image2.png',\n    'image3.png',\n    ],\n    media_type='IMAGE',\n)\n\ncompared_media = service.compare_media(request)\n</code></pre> <p><code>compare_media</code> returns list of <code>MediaSimilarityComparisonResult</code> objects each containing the following properties:</p> <ul> <li><code>media_pair_identifier</code> - identifier of a media pair (pipe separated media ids of two media).</li> <li><code>similarity_score</code> - contains information on number of similar / dissimilar tags and their weights.</li> </ul> <p><code>MediaSimilarityComparisonResult</code> can be written to local / remote storage via garf-io with <code>to_garf_report</code> method with the following columns:</p> <ul> <li><code>media_pair_identifier</code> - identifier of a media pair (pipe separated media ids of two media).</li> <li><code>score</code> - similarity score for media pair.</li> <li><code>similar_tags</code> - number of common tags between media.</li> <li><code>similarity_weight_normalized</code> - weight of similar tags normalized by inverse-document frequency.</li> <li><code>similarity_weight_unnormalized</code> - weight of similar tags.</li> <li><code>dissimilar_tags</code>- number of dissimilar tags between media.</li> <li><code>dissimilarity_weight_normalized</code> - weight of dissimilar tags normalized by inverse-document frequency.</li> <li><code>dissimilarity_weight_unnormalized</code> - weight of dissimilar tags.</li> </ul>"},{"location":"similarity/persistence/","title":"Persisting Similarity Results","text":"<p>By default when analyzing media similarity all intermediate data is saved in the memory.</p> <p>You can opt-in to persisting data in the database of your choice.</p> <p>If you're analyzing similarity of the same media pair for the second time its similarity information will be fetched from DB instead of performing actual similarity calculation.</p>"},{"location":"similarity/persistence/#using-shared-database","title":"Using shared database","text":"<p>The easiest option is to use a single database for tagging and similarity results.</p> clipython <pre><code>media-similarity cluster image1.png image2.png image3.png \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --db-uri sqlite:///tagging.db\n</code></pre> <pre><code>from media_similarity import MediaClusteringRequest, MediaSimilarityService\nfrom media_similarity.repositories import SqlAlchemySimilarityResultsRepository\n\nrepository = SqlAlchemySimilarityResultsRepository('sqlite:///tagging.db')\nservice = MediaSimilarityService(repository)\n\nrequest = MediaClusteringRequest(\n  media_paths=[\n    'image1.png',\n    'image2.png',\n    'image3.png',\n    ],\n    media_type='IMAGE',\n    tagger_type='gemini',\n)\n\nclusters = service.cluster_media(request)\n</code></pre>"},{"location":"similarity/persistence/#using-dedicated-databases","title":"Using dedicated databases","text":"<p>You can use two different databases for tagging and similarity results.</p> clipython <pre><code>media-similarity cluster image1.png image2.png image3.png \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --db-uri sqlite:///similarity.db \\\n  --tagging.db_uri=sqlite:///tagging.db\n</code></pre> <pre><code>import media_tagging\nfrom media_similarity import MediaClusteringRequest, MediaSimilarityService\n\nfrom media_tagging.repositories import SqlAlchemyTaggingResultsRepository\nfrom media_similarity.repositories import SqlAlchemySimilarityResultsRepository\n\ntagging_repository = SqlAlchemyTaggingResultsRepository('sqlite:///tagging.db')\n\ntagging_service = media_tagging.MediaTaggingService(tagging_repository)\nrepository = SqlAlchemySimilarityResultsRepository('sqlite:///similarity.db')\n\nservice = MediaSimilarityService(\n  media_similarity_repository=repository,\n  tagging_service=tagging_service)\n\nrequest = MediaClusteringRequest(\n  media_paths=[\n    'image1.png',\n    'image2.png',\n    'image3.png',\n    ],\n    media_type='IMAGE',\n    tagger_type='gemini',\n)\n\nclusters = service.cluster_media(request)\n</code></pre>"},{"location":"similarity/search/","title":"Search","text":""},{"location":"similarity/search/#searching-for-similar-media","title":"Searching for similar media","text":"<p><code>media-similarity</code> can search for similar media given a set of seed media.</p> <p>Please note that this requires persistence setup.</p> clipython <pre><code>media-similarity search image3 \\\n  --media-type IMAGE \\\n  --db-uri=&lt;CONNECTION_STRING&gt;\n</code></pre> <pre><code>from media_similarity import MediaSimilaritySearchRequest, MediaSimilarityService\n\nservice = MediaSimilarityService.from_connecting_string(\n  'sqlite:///tagging_results.db'\n)\n\nrequest = MediaSimilaritySearchRequest(\n  media_paths=[\n    'image3.png',\n    ],\n    media_type='IMAGE',\n    n_results=1,\n)\n\nsimilar_media = service.find_similar_media(request)\n</code></pre>"},{"location":"tagging/file-loader/","title":"Loading files from CSV","text":"<p>If loading tagging results with <code>file</code> loader, the CSV file should contains the following columns:</p>"},{"location":"tagging/file-loader/#csv-schema","title":"CSV Schema","text":"<ul> <li><code>media_url</code> - location of medium (can be remote or local).</li> <li><code>tag</code> - column that contains name of a tag.</li> <li><code>score</code> - column that contains prominence of a tag in the media.</li> </ul>"},{"location":"tagging/gemini/","title":"Tagging media with Gemini","text":""},{"location":"tagging/gemini/#prerequisites","title":"Prerequisites","text":"<ul> <li>Google Cloud Project with billing account attached</li> <li>Either Vertex AI API enabled or GOOGLE_API_KEY to access Google Gemini.</li> </ul>"},{"location":"tagging/gemini/#supported-media","title":"Supported media","text":"<ul> <li>IMAGE</li> <li>VIDEO</li> <li>YOUTUBE_VIDEO</li> <li>TEXT</li> <li>WEBPAGE (only for <code>gemini-2.5-*</code> models)</li> </ul>"},{"location":"tagging/gemini/#installation","title":"Installation","text":"pipuv <pre><code>pip install media-tagging\n</code></pre> <pre><code>uv pip install media-tagging\n</code></pre>"},{"location":"tagging/gemini/#usage","title":"Usage","text":"<p>Expose necessary environmental variables before using Gemini tagger.</p> Gemini Developer APIGemini API in Vertex AI <pre><code>export GOOGLE_API_KEY=&lt;YOUR_API_KEY_HERE&gt;\n</code></pre> <pre><code>export GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT=&lt;YOUR_PROJECT_HERE&gt;\nexport GOOGLE_CLOUD_LOCATION=&lt;YOUR_CLOUD_LOCATION_HERE&gt;\n</code></pre> <p>Run <code>media-tagger</code> with Gemini tagger.</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n)\n\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ]\n  }'\n</code></pre>"},{"location":"tagging/gemini/#tagger-customizations","title":"Tagger customizations","text":""},{"location":"tagging/gemini/#video","title":"Video","text":"<p>For <code>VIDEO</code> and <code>YOUTUBE_VIDEO</code> media types you can specify video specific parameters (<code>fps</code>, <code>start_offset</code>, <code>end_offset</code>)</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type YOUTUBE_VIDEO \\\n  --tagger gemini \\\n  --tagger.fps=5 \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='VIDEO',\n  media_paths=['video1.mp4', 'video2.mp4'],\n  tagger_type='gemini',\n  tagging_options={\n    'fps': 5,\n  },\n)\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"VIDEO\",\n    \"media_paths\": [\n      \"video1.mp4\",\n      \"video2.mp4\"\n    ],\n    \"tagging_options\": {\n      \"fps\": 5\n    }\n    \"\n  }'\n</code></pre>"},{"location":"tagging/google-cloud/","title":"Tagging media with Google Cloud APIs","text":""},{"location":"tagging/google-cloud/#prerequisites","title":"Prerequisites","text":"<ul> <li>A GCP project with billing account attached</li> <li>Video Intelligence API and Vision API enabled.</li> </ul>"},{"location":"tagging/google-cloud/#supported-media","title":"Supported media","text":"<ul> <li>IMAGE</li> <li>VIDEO</li> </ul>"},{"location":"tagging/google-cloud/#installation","title":"Installation","text":"pipuv <pre><code>pip install media-tagging[google-cloud]\n</code></pre> <pre><code>uv pip install media-tagging[google-cloud]\n</code></pre> <p>If you want to use server capabilities of <code>media-tagger</code> you need to install additional dependencies:</p> <pre><code>pip install media-tagging[server]\n</code></pre>"},{"location":"tagging/google-cloud/#usage","title":"Usage","text":"<p>Important</p> <p><code>google-cloud</code> tagger only supports <code>tag</code> command.</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger google-cloud\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='google-cloud',\n)\n\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"google-cloud\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ]\n  }'\n</code></pre>"},{"location":"tagging/google-cloud/#n_tags","title":"n_tags","text":"<p><code>google-cloud</code> tag support <code>n_tags</code> parameter to limit number of tags returned from API. Learn more.</p>"},{"location":"tagging/langchain/","title":"Langchain","text":""},{"location":"tagging/langchain/#tagging-media-with-langchain","title":"Tagging media with Langchain","text":"<p>If you're working with images you can use the multimodal LLMs supported by Langchain.</p>"},{"location":"tagging/langchain/#prerequisites","title":"Prerequisites","text":"<ul> <li>A concrete Langchain library installed and configured</li> </ul>"},{"location":"tagging/langchain/#supported-media","title":"Supported media","text":"<ul> <li>IMAGE</li> </ul>"},{"location":"tagging/langchain/#installation","title":"Installation","text":"pipuv <pre><code>pip install media-tagging-langchain\n</code></pre> <pre><code>uv pip install media-tagging-langchain\n</code></pre> <p>If you want to use server capabilities of <code>media-tagger</code> you need to install additional dependencies:</p> <pre><code>pip install media-tagging[server]\n</code></pre>"},{"location":"tagging/langchain/#usage","title":"Usage","text":"clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger langchain \\\n  --tagger.llm_class_name=&lt;FULLY_QUALIFIED_CLASS_NAME&gt;\n</code></pre> <p>Where</p> <ul> <li><code>&lt;FULLY_QUALIFIED_CLASS_NAME&gt;</code> - fully path to the LLM class (i.e. <code>langchain_google_genai.ChatGoogleGenerativeAI</code>). Corresponding library should be installed before calling the <code>media-tagger</code>.</li> </ul> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\n\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='langchain',\n  tagging_options={\n    'llm_class_name': 'langchain_google_genai.ChatGoogleGenerativeAI',\n  }\n)\n\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"langchain\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ],\n    \"tagging_options\": {\n      \"llm_class_name\": \"langchain_google_genai.ChatGoogleGenerativeAI\"\n    }\n  }'\n</code></pre>"},{"location":"tagging/loading/","title":"Loading","text":"<p>If you want to import tags to be used later, you can use <code>media-loader</code> utility.</p> <p><pre><code>media-loader PATH_TO_FILE \\\n  --media-type &lt;MEDIA_TYPE&gt; \\\n  --loader &lt;LOADER_TYPE&gt; \\\n  --db-uri=&lt;CONNECTION_STRING&gt; \\\n  --action &lt;ACTION&gt;\n</code></pre> where:</p> <ul> <li><code>&lt;MEDIA_TYPE&gt;</code> - one of supported media types. <p>For YouTube file uploads specify YOUTUBE_VIDEO type.</p> </li> <li><code>&lt;LOADER_TYPE&gt;</code> - one of supported loader types. <p>Loader can be customized via <code>loader.option=value</code> syntax. I.e. if you want to change the default column name with media tags are located you can specify <code>--loader.tag_name=new_column_name</code> CLI flag.</p> </li> <li><code>&lt;CONNECTION_STRING&gt;</code> - Connection string to the database with tagging results (i.e. <code>sqlite:///tagging.db</code>).</li> <li><code>ACTION</code> - either <code>tag</code> or <code>describe</code>.</li> </ul> <p>If loading tagging results with <code>file</code> loader, the CSV file should contains the following columns:</p> <ul> <li><code>media_url</code> - location of medium (can be remote or local).</li> <li><code>tag</code> - column that contains name of a tag.</li> <li><code>score</code> - column that contains prominence of a tag in the media.</li> </ul>"},{"location":"tagging/loading/#loaders","title":"Loaders","text":"<ul> <li><code>file</code> - loads tags from a CSV file</li> </ul>"},{"location":"tagging/media/","title":"What is Media?","text":"<p>Media represent files, texts, etc. which contains audio-visual elements.</p> <p>Each media consist of several elements:</p> <ul> <li><code>media_path</code> - location where media can be found.</li> <li><code>media_type</code> - type of media, see supported media types.</li> <li><code>name</code> - optional name of the media, if not specified then name of base file name is used for file-based media.</li> <li><code>content</code> - optional byte representation of a medium.</li> </ul>"},{"location":"tagging/media/#supported-media-types","title":"Supported media types","text":"<ul> <li>IMAGE</li> <li>VIDEO</li> <li>TEXT</li> <li>YOUTUBE_VIDEO</li> <li>WEBPAGE</li> </ul> <p>Media can be located somewhere (local file, GCS / S3 bucket, URL) or present as is (i.e. text, page url).</p>"},{"location":"tagging/overview/","title":"Overview","text":"<p><code>media-tagger</code> performs tagging of supported media based on various taggers. It generates tagging results which can written to local / remove storage or further processed in Python.</p>"},{"location":"tagging/overview/#key-features","title":"Key features","text":"<ul> <li>Extracts semantic tags from media.</li> <li>Describes media using custom prompt and schema.</li> <li>Saves results of tagging / description to files / databases.</li> </ul>"},{"location":"tagging/overview/#supported-taggers","title":"Supported taggers","text":"<ul> <li>gemini</li> <li>google-cloud</li> <li>langchain</li> </ul>"},{"location":"tagging/overview/#installation","title":"Installation","text":"<p><code>media-tagger</code> installation depends on which tagger you want to use.</p> geminigoogle-cloudlangchain <pre><code>pip install media-tagging\n</code></pre> <pre><code>pip install media-tagging[google-cloud]\n</code></pre> <pre><code>pip install media-tagging media-tagging-langchain\n</code></pre> <p>If you want to use server capabilities of <code>media-tagger</code> you need to install additional dependencies:</p> <pre><code>pip install media-tagging[server]\n</code></pre>"},{"location":"tagging/overview/#usage","title":"Usage","text":"<p><code>media-tagger</code> supports the following commands:</p> <ul> <li>tag</li> <li>describe</li> </ul>"},{"location":"tagging/overview/#tag-media","title":"Tag media","text":"<p>Tagging returns multiple tags for a single media. Each tag has a name and a score from 0 to 1.</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\n\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n)\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ]\n  }'\n</code></pre>"},{"location":"tagging/overview/#n_tags","title":"n_tags","text":"<p>By default <code>media-tagger</code> returns only 10 tags for the media. You can change this number with <code>n_tags</code> parameter.</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --tagger.n_tags=100 \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n  tagging_options={'n_tags': 100},\n)\n\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ],\n    \"tagging_options\": {\n      \"n_tags\": 100\n    }\n    \"\n  }'\n</code></pre>"},{"location":"tagging/overview/#tags","title":"tags","text":"<p>You can use <code>media-tagger</code> to find specific tags in your media using <code>tags</code> parameter.</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --tagger.tags='cat,dog,human' \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n  tagging_options={'tags': ['cat', 'dog', 'human']},\n)\n\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ],\n    \"tagging_options\": {\n      \"tags\": \"cat,dog,human\"\n    }\n    \"\n  }'\n</code></pre>"},{"location":"tagging/overview/#describe-media","title":"Describe media","text":"<p>Description answer the question \"What this media is about?\".</p> clipythoncurl <pre><code>media-tagger describe MEDIA_PATHs \\\n  --media-type &lt;MEDIA_TYPE&gt; \\\n  --tagger &lt;TAGGER_TYPE&gt; \\\n  --writer &lt;WRITER_TYPE&gt; \\\n  --output &lt;OUTPUT_FILE_NAME&gt;\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\n\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n)\nresult = media_tagger.describe_media(request)\n\nresult.save(output='description_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/describe' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ]\n    \"\n  }'\n</code></pre>"},{"location":"tagging/overview/#custom_prompt","title":"custom_prompt","text":"<p>If you want to change the default prompt used when describing media you can specify <code>custom_prompt</code> parameter. <code>custom_prompt</code> can be either a prompt or a file path (local or remote) with <code>.txt</code> extension.</p> clipythoncurl <pre><code>media-tagger describe MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --tagger.custom_prompt=\"Is this an advertising? Answer only True or False\" \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n  tagging_options={\n    'custom_prompt': 'Is this an advertising? Answer only True or False'\n  },\n)\n\nresult = media_tagger.describe_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/describe' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ],\n    \"tagging_options\": {\n      \"custom_prompt\": \"Is this an advertising? Answer only True or False\"\n    }\n    \"\n  }'\n</code></pre>"},{"location":"tagging/overview/#custom_schema","title":"custom_schema","text":"<p>When passing custom prompt you can opt out of using built in schemas in <code>media-tagger</code> by using <code>--tagger.no-schema=True</code> or provide a custom schema via <code>custom_schema</code> parameter.</p> clipythoncurl <pre><code>media-tagger describe MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --tagger.custom_prompt=\"Is this an advertising? Answer only True or False\" \\\n  --tagger.custom_schema=./schema.json \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\nimport pydantic\n\n\nclass CustomSchema(pydantic.BaseModel):\n  answer: bool\n\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n  tagging_options={\n    'custom_prompt': 'Is this an advertising? Answer only True or False',\n    'custom_schema': CustomSchema,\n  },\n)\n\nresult = media_tagger.describe_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/describe' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ],\n    \"tagging_options\": {\n      \"custom_prompt\": \"Is this an advertising? Answer only True or False\",\n      \"custom_schema\": \"schema.json\"\n    }\n    \"\n  }'\n</code></pre>"},{"location":"tagging/overview/#common-tagger-parameters","title":"Common tagger parameters","text":"<p>All the taggers support the following parameters.</p>"},{"location":"tagging/overview/#n_runs","title":"n_runs","text":"<p><code>n_runs=N</code> parameter to repeat tagging process <code>N</code> times.</p> clipythoncurl <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --tagger.n_runs=10 \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\n\nmedia_tagger = media_tagging.MediaTaggingService()\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n  tagging_options={\n    'n_runs': 10,\n  },\n)\n\nresult = media_tagger.tag_media(request)\n\nresult.save(output='tagging_results', writer='csv')\n</code></pre> <p>Start API by running <code>python -m media_tagging.entrypoints.server</code>.</p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/media_tagging/tag' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"tagger_type\": \"gemini\",\n    \"media_type\": \"IMAGE\",\n    \"media_paths\": [\n      \"image1.png\",\n      \"image2.png\"\n    ],\n    \"tagging_options\": {\n      \"n_runs\": 10\n    }\n    \"\n  }'\n</code></pre>"},{"location":"tagging/persistence/","title":"Save results of tagging in DB","text":"<p>By default when doing tagging all intermediate data is saved in the memory.</p> <p>You can opt-in to persisting data in the database of your choice.</p> <p>If you're tagging the same media and the same tagger for the second time its tags will be fetched from DB instead of calling API to perform the tagging.</p> clipython <pre><code>media-tagger tag MEDIA_PATHs \\\n  --media-type IMAGE \\\n  --tagger gemini \\\n  --db-uri sqlite:///tagging.db \\\n  --writer csv \\\n  --output tagging_results\n</code></pre> <pre><code>import media_tagging\nfrom media_tagging.repositories import SqlAlchemyTaggingResultsRepository\n\nrepository = SqlAlchemyTaggingResultsRepository('sqlite:///tagging.db')\nmedia_tagger = media_tagging.MediaTaggingService(repository)\n\nrequest = media_tagging.MediaTaggingRequest(\n  media_type='IMAGE',\n  media_paths=['image1.png', 'image2.png'],\n  tagger_type='gemini',\n)\n\nresult = media_tagger.tag_media(request)\n</code></pre>"},{"location":"tagging/tagging-result/","title":"Results of tagging","text":""},{"location":"tagging/tagging-result/#taggingresult","title":"TaggingResult","text":"<p>Once tagging is done you get a <code>TaggingResult</code>.</p> <p><code>TaggingResult</code> contains results of tagging for a single medium and contains the following elements:</p> <ul> <li><code>processed_at</code> - time when medium was processed.</li> <li><code>identifier</code> - unique identifier of medium. For file based media - base path without extension, for YouTube video - video_id, for texts - text itself.</li> <li><code>type</code> - type of medium.</li> <li><code>content</code> - result of tagging. Can be either array of Tag or one or many Descriptions.</li> <li><code>tagger</code> -  type of tagger used for tagging this medium.</li> <li><code>output</code> - type of operation on medium  - either tag or description.</li> <li><code>tagging_details</code> - Any details used to perform the tagging, for example custom_prompt, number of tags requested.</li> </ul> tagsdescriptiondescriptions <pre><code>from media_tagging import tagging_result\n\nresult = tagging_result.TaggingResult(\n  tagger='gemini',\n    type='IMAGE',\n    output='tag',\n    content=[\n      tagging_result.Tag(name='tag_name_1', score=1.0),\n      tagging_result.Tag(name='tag_name_1', score=0.1),\n    ],\n    tagging_details={'n_tags': 2},\n</code></pre> <pre><code>from media_tagging import tagging_result\n\nresult = tagging_result.TaggingResult(\n  tagger='gemini',\n    type='IMAGE',\n    output='tag',\n    content= tagging_result.Description(text='True'),\n    tagging_details={\n      'custom_prompt': 'Is this an advertising. Answer only True or False'\n    },\n</code></pre> <pre><code>from media_tagging import tagging_result\n\nresult = tagging_result.TaggingResult(\n  tagger='gemini',\n    type='IMAGE',\n    output='tag',\n    content=\n      tagging_result.Description(text='00:00:05'),\n      tagging_result.Description(text='00:00:15'),\n    ],\n    tagging_details={\n      'custom_prompt': 'Find all the timestamps where a cat appears'\n    },\n</code></pre> <p>You can extract tags / descriptions themself via <code>.content</code> property</p> <pre><code>tags = results.content\n</code></pre>"},{"location":"tagging/tagging-result/#tag","title":"Tag","text":"<p><code>Tag</code> represents a unique concept (using a singular noun) with a score from 0 to 1 where 0 is an absence of a concept and 1 is a total presence.</p> <p>Usually a single media is tagged with multiple tags with varying scores.</p> <pre><code>from media_tagging import tagging_result\n\ntag = tagging_result.Tag(name='tag_name_1', score=0.1)\n</code></pre>"},{"location":"tagging/tagging-result/#trimming-tags","title":"Trimming tags","text":"<p>If <code>TaggingResult</code> contains tags you can trim them by removing those which scores lower than a custom threshold. This can be useful when <code>media-tagger</code> provides a lot of non-definitive tags.</p> <pre><code>result.trim_tags(0.5)\n</code></pre>"},{"location":"tagging/tagging-result/#description","title":"Description","text":"<p><code>Description</code> contains an information on a media in a form of a text or JSON.</p> <pre><code>from media_tagging import tagging_result\n\ndescription = tagging_result.Description(text='This is an advertising.')\n</code></pre>"}]}